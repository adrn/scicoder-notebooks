{
 "metadata": {
  "name": "project-SEGUE"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from astropy.io import fits, ascii\n",
      "import astropy.coordinates as coord\n",
      "from matplotlib import rcParams"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We'll start by modifying our plot defaults so we don't have to set as many parameters below:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rcParams['lines.marker'] = '.' # set the marker to a point\n",
      "rcParams['lines.markersize'] = 4 # make the point small!\n",
      "rcParams['lines.linestyle'] = 'none' # we're going to make a lot of scatter plots"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First we'll open the SSPP (SEGUE data pipeline) data file, containing derived spectral parameters for 1843200 stars in SDSS. Each row represents data for one star. The file is a bit large, so we use `memmap=True` to use the memory-mapping feature, which handles large files better."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hdulist = fits.open(\"data/ssppOut-dr9.fits\", memmap=True)\n",
      "hdulist.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you can see from the info, there are two HDU's: HDU0 is an empty image HDU, and HDU1 is a table. The table has 239 columns and 1843200 rows. That's our data! If your computer has enough RAM, you should be able to load this into an array like this:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_data = hdulist[1].data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can take a look at the column names:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_data.dtype.names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first group of columns are SDSS bit flags and survey info about the targets. Starting around __SPECTYPE_HAMMER__, they start to get interesting. __SPECTYPE_HAMMER__ and __SPECTYPE_SUBCLASS__ are attempts to classify the spectrum of the star. A little further down, notice there are a ton of columns starting with __TEFF__. These are different methods for measuring the effective temperature of the star. Similarly, __LOGG__ (surface gravity) and __FEH__ (metallicity) have a bunch of measurements as well. We're going to stick to using the adopted values, __TEFF_ADOP__, __LOGG_ADOP__, and __FEH_ADOP__."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "unq_spectral_types = np.unique(all_data['SPECTYPE_HAMMER'])\n",
      "print unq_spectral_types"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The best data are the spectra for which no flags are triggered. These have the __FLAG__ keyword set to 'nnnnn'. We're going to first look at the radial velocities, metallicities, and distances to these 'best' stars. An additional check for bad data is to mask out any values set to -9999, which SDSS uses to mean 'bad' (FYI, that was a really bad choice!)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best_data = all_data[all_data['FLAG'] == 'nnnnn']\n",
      "best_data = best_data[(best_data['RV_ADOP'] != -9999) & \\\n",
      "                      (best_data['FEH_ADOP'] != -9999) & \\\n",
      "                      (best_data['DIST_AP'] != -9999)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we'll use the SDSS API to pull down spectra of each spectral type, interpolate onto the same wavelength grid, and coadd. The API requires a Plate ID, MJD date of observation, and a Fiber ID and returns as JSON spectrum. For this, we'll write a `Spectrum` class."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy import interpolate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Spectrum(object):\n",
      "    \n",
      "    def __init__(self, wavelength, flux):\n",
      "        \"\"\" Represents a 1D spectrum with a dispersion measured in\n",
      "            wavelength.\n",
      "        \"\"\"\n",
      "        self.wvln = np.array(wavelength)\n",
      "        self.flux = np.array(flux)\n",
      "    \n",
      "    def interpolate(self, new_grid, **interp1d_kwargs):\n",
      "        \"\"\" Interpolate this spectrum onto the new grid and return a \n",
      "            new Spectrum object.\n",
      "        \"\"\"\n",
      "        interp_func = interpolate.interp1d(self.wvln, self.flux, **interp1d_kwargs)\n",
      "        new_flux = interp_func(new_grid)\n",
      "        \n",
      "        return Spectrum(new_grid, new_flux)\n",
      "    \n",
      "    def __add__(self, other):\n",
      "        if (self.wvln == other.wvln).all():\n",
      "            return Spectrum(self.wvln, self.flux + other.flux)\n",
      "        else:\n",
      "            raise ValueError(\"Wavelength grids must match to add!\")\n",
      "    \n",
      "    def plot(self, ax=None, **kwargs):\n",
      "        if ax == None:\n",
      "            plot(self.wvln, self.flux, **kwargs)\n",
      "            xlim(self.wvln.min(), self.wvln.max())\n",
      "        else:\n",
      "            ax.plot(self.wvln, self.flux, **kwargs)\n",
      "            ax.set_xlim(self.wvln.min(), self.wvln.max())\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests\n",
      "api_url = \"http://api.sdss3.org/spectrum\"\n",
      "\n",
      "def spectra_for_type(spectype, N=10):\n",
      "    spectype_data = best_data[best_data['SPECTYPE_HAMMER'] == spectype]\n",
      "    \n",
      "    spectra = []\n",
      "    for ii in np.random.randint(len(spectype_data), size=N):\n",
      "        params = dict(plate=spectype_data[ii]['PLATE'],\n",
      "                      fiber=spectype_data[ii]['FIBER'],\n",
      "                      mjd=spectype_data[ii]['MJD'],\n",
      "                      format='json')\n",
      "        r = requests.get(api_url, params=params)\n",
      "        resp = r.json()\n",
      "        spectra.append(Spectrum(wavelength=resp['wavelengths'], flux=resp['flux']))\n",
      "    \n",
      "    return spectra"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "spectra = spectra_for_type('F0', N=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coadded_spectrum = spectra[0]\n",
      "for s in spectra[1:]:\n",
      "    ispec = s.interpolate(coadded_spectrum.wvln, bounds_error=False)\n",
      "    coadded_spectrum = coadded_spectrum + ispec\n",
      "\n",
      "figure(figsize=(14,6))\n",
      "coadded_spectrum.plot(linestyle='-', marker=None, drawstyle='steps')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's look at a histogram of the radial velocities, metallicities, and distances for these best data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(12,5))\n",
      "\n",
      "subplot(131)\n",
      "x = hist(best_data['RV_ADOP'], bins=100)\n",
      "xlim(-500, 500)\n",
      "xlabel(\"RV [km/s]\")\n",
      "\n",
      "subplot(132)\n",
      "x = hist(best_data['FEH_ADOP'], bins=100)\n",
      "xlabel(\"[Fe/H]\")\n",
      "\n",
      "subplot(133)\n",
      "x = hist(best_data['DIST_AP'], bins=np.linspace(0., 50, 100))\n",
      "xlabel(\"$D_\\odot$ [kpc]\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we need to transform from heliocentric to Galactocentric coordinates. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def helio_to_galacto(l, b, D):\n",
      "    \"\"\" Convert from heliocentric Galactic longitude, latitude, \n",
      "        and distance to Galactocentric cartesian coordinates.\n",
      "    \"\"\"\n",
      "    # b defined from -90 to 90, shift to 0 to 180\n",
      "    b = b + 90.*u.degree\n",
      "    \n",
      "    X = D*np.sin(b.radian)*np.cos(l.radian)\n",
      "    X -= 8*u.kpc\n",
      "    Y = D*np.sin(b.radian)*np.sin(l.radian)\n",
      "    Z = D*np.cos(b.radian)\n",
      "    \n",
      "    return X,Y,Z"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(16,5))\n",
      "\n",
      "subplot(141)\n",
      "x = hist(best_data['RV_ADOP'], bins=100)\n",
      "xlim(-500, 500)\n",
      "xlabel(\"RV [km/s]\")\n",
      "\n",
      "subplot(142)\n",
      "x = hist(best_data['FEH_ADOP'], bins=100)\n",
      "xlabel(\"[Fe/H]\")\n",
      "\n",
      "subplot(143)\n",
      "X,Y,Z = helio_to_galacto(best_data['L']*u.deg,\n",
      "                         best_data['B']*u.deg,\n",
      "                         best_data['DIST_AP']*u.kpc)\n",
      "D_gc = np.sqrt(X**2+Y**2+Z**2)\n",
      "x = hist(D_gc, bins=np.linspace(0., 50, 100))\n",
      "xlabel(\"$D_{gc}$ [kpc]\")\n",
      "\n",
      "subplot(144)\n",
      "x = hist(Z, bins=np.linspace(0., 50, 100))\n",
      "xlabel(\"$Z_{gc}$ [kpc]\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's select all stars with a metallicity < -1, and color them differently:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "idx = best_data['FEH_ADOP'] < -1\n",
      "metal_cut_stars = best_data[idx]\n",
      "other_stars = best_data[np.logical_not(idx)]\n",
      "\n",
      "figure(figsize=(16,5))\n",
      "\n",
      "subplot(141)\n",
      "h,bins = np.histogram(best_data['RV_ADOP'], bins=100)\n",
      "x = hist(other_stars['RV_ADOP'], bins=bins, color='k', alpha=0.5)\n",
      "x = hist(metal_cut_stars['RV_ADOP'], bins=bins, color='r', alpha=0.5)\n",
      "xlim(-500, 500)\n",
      "xlabel(\"RV [km/s]\")\n",
      "\n",
      "subplot(142)\n",
      "h,bins = np.histogram(best_data['FEH_ADOP'], bins=100)\n",
      "x = hist(other_stars['FEH_ADOP'], bins=bins, color='k', alpha=0.5)\n",
      "x = hist(metal_cut_stars['FEH_ADOP'], bins=bins, color='r', alpha=0.5)\n",
      "xlabel(\"[Fe/H]\")\n",
      "\n",
      "subplot(143)\n",
      "bins = np.linspace(0., 50, 100)\n",
      "x = hist(D_gc[np.logical_not(idx)], bins=bins, color='k', alpha=0.5)\n",
      "x = hist(D_gc[idx], bins=bins, color='r', alpha=0.5)\n",
      "xlabel(\"$D_{gc}$ [kpc]\")\n",
      "\n",
      "subplot(144)\n",
      "bins = np.linspace(0., 50, 100)\n",
      "x = hist(Z[np.logical_not(idx)], bins=bins, color='k', alpha=0.5)\n",
      "x = hist(Z[idx], bins=bins, color='r', alpha=0.5)\n",
      "xlabel(\"$Z_{gc}$ [kpc]\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Cool! The low metallicity stars have a larger velocity dispersion, and go to much larger distances -- consistent with our understanding of the thick disk and Galactic halo."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we'll make an all-sky plot in Galactic coordinates, with a point for each star in SEGUE colored by its radial velocity."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = best_data[(np.abs(best_data['RV_ADOP']) < 50)]\n",
      "rv = data['RV_ADOP']\n",
      "l,b = data['L'], data['B']\n",
      "\n",
      "fig = figure(figsize=(14,12))\n",
      "ax = fig.add_subplot(111, projection=\"mollweide\")\n",
      "\n",
      "#l -= 180\n",
      "l = l*u.degree\n",
      "b = b*u.degree\n",
      "sc = ax.scatter(l.radian, b.radian, marker='.', \n",
      "                c=rv, edgecolor='none', cmap=cm.brg,\n",
      "                alpha=0.25, s=4)\n",
      "colorbar(sc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def box_select(ra_cen, dec_cen, ra_size, dec_size):\n",
      "    ra_min, ra_max = ra_cen-ra_size/2., ra_cen+ra_size/2.\n",
      "    dec_min, dec_max = dec_cen-dec_size/2., dec_cen+dec_size/2.\n",
      "    data = best_data[(best_data['RA'] > ra_min.degree) & (best_data['RA'] < ra_max) & \\\n",
      "                     (best_data['DEC'] > dec_min) & (best_data['DEC'] < dec_max)]\n",
      "    \n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clusters = ascii.read(\"data/sdss_clusters.txt\", names=['name', 'size_arcmin'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "R_gcs = []\n",
      "FeHs = []\n",
      "Zs = []\n",
      "for cluster in clusters:\n",
      "    eq = coord.ICRSCoordinates.from_name(cluster['name'])\n",
      "    selected = box_select(eq.ra.degrees, eq.dec.degrees, \n",
      "                          cluster['size_arcmin']/60., cluster['size_arcmin']/60.)\n",
      "    \n",
      "    idx = (selected['DIST_ADOP'] > -9999) & (selected['FEH_ADOP'] > -9999)\n",
      "    selected = selected[idx]\n",
      "    \n",
      "    if len(selected) < 2:\n",
      "        continue\n",
      "        \n",
      "    X,Y,Z = helio_to_galacto(selected['L']*u.degree, \n",
      "                             selected['B']*u.degree,\n",
      "                             selected['DIST_ADOP']*u.kpc)\n",
      "    R_gcs.append(np.median(np.sqrt(X**2 + Y**2 + Z**2)))\n",
      "    FeHs.append(np.median(selected['FEH_ADOP']))\n",
      "    Zs.append(np.median(Z))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figsize(14,8)\n",
      "plot(R_gcs, FeHs, marker='o', linestyle='none')\n",
      "xlabel(\"Galactocentric Distance [kpc]\")\n",
      "ylabel(\"Metallicity [Fe/H]\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another thing we can do is look at Color-Color plots for these 'best' data. We'll first look at $u-g$ vs. $g-r$, then see if any of these colors correlate with stellar parameters like $T_{eff}$ or $\\log(g)$. Before that, let's make sure the data we plot has color values by masking out -9999 in the colors:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# note: UG stands for u-g\n",
      "best_data = best_data[(best_data['UG'] != -9999) & \\\n",
      "                      (best_data['GR'] != -9999) & \\\n",
      "                      (best_data['RI'] != -9999) & \\\n",
      "                      (best_data['IZ'] != -9999)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(5,5))\n",
      "plot(best_data['UG'], best_data['GR'], alpha=0.1)\n",
      "xlim(-0.5, 3.5)\n",
      "ylim(-0.5, 2.)\n",
      "xlabel(r'$u-g$')\n",
      "ylabel(r'$g-r$')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Nice! But now let's make a few more projections of the data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig,axes = subplots(2,2,figsize=(8,8), sharex=True, sharey=True)\n",
      "axes[0,0].plot(best_data['UG'], best_data['GR'], alpha=0.1)\n",
      "axes[1,0].plot(best_data['UG'], best_data['RI'], alpha=0.1)\n",
      "axes[1,1].plot(best_data['GR'], best_data['RI'], alpha=0.1)\n",
      "axes[0,1].set_visible(False)\n",
      "\n",
      "# we have to set the labels manually\n",
      "axes[0,0].set_ylabel(\"$g-r$\")\n",
      "axes[1,0].set_xlabel(\"$u-g$\")\n",
      "axes[1,0].set_ylabel(\"$r-i$\")\n",
      "axes[1,1].set_xlabel(\"$g-r$\")\n",
      "\n",
      "# the plots share axes, so we only have to set these for one \n",
      "axes[1,1].set_xlim(-1., 3.5)\n",
      "axes[1,1].set_ylim(-.5, 1.5)\n",
      "\n",
      "# adjust the spacing so the subplots are closer\n",
      "fig.subplots_adjust(wspace=0.1, hspace=0.1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's say we want to plot, like before, a subset of points in a different color. We could copy and paste all of those plot commands, but instead we could write a function that accepts a list of data objects, and a list of style argument dictionaries and plots them in sequence. Let's also add the 4th color dimension here ($i-z$)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def color_color(data_list, style_list, xlim=(-1., 3.5), ylim=(-.5, 1.5)):\n",
      "    \"\"\" Given a list of data, and a list of style dictionaries, make \n",
      "        color-color plots but overplot all of the data on the same figure.\n",
      "    \"\"\"\n",
      "    colors = ['UG', 'GR', 'RI', 'IZ']\n",
      "    \n",
      "    fig,axes = subplots(len(colors),len(colors),figsize=(12,12))\n",
      "    \n",
      "    for data,style in zip(data_list, style_list):\n",
      "        for ii,color1 in enumerate(colors):\n",
      "            for jj,color2 in enumerate(colors):\n",
      "                if jj > ii:\n",
      "                    # duplicate plots - we only want the lower 'tringle' of plots\n",
      "                    axes[ii,jj].set_visible(False)\n",
      "                    continue\n",
      "                elif ii == jj:\n",
      "                    # plotting color vs. color - make a histogram instead\n",
      "                    bins = np.linspace(xlim[0], xlim[1], 100)\n",
      "                    axes[ii,jj].hist(data[color1], bins=bins, **style)\n",
      "                    axes[ii,jj].set_xticklabels([])\n",
      "                    axes[ii,jj].set_yticklabels([])\n",
      "                    continue\n",
      "                \n",
      "                axes[ii,jj].plot(data[color2], data[color1], **style)\n",
      "                \n",
      "                # the first column, so we want ylabels\n",
      "                if jj == 0:\n",
      "                    axes[ii,jj].set_ylabel(\"${0[0]}-{0[1]}$\".format(color1.lower()))\n",
      "                else:\n",
      "                    axes[ii,jj].set_yticklabels([])\n",
      "                \n",
      "                # the last row, so we want xlabels\n",
      "                if ii == (len(colors)-1):\n",
      "                    axes[ii,jj].set_xlabel(\"${0[0]}-{0[1]}$\".format(color2.lower()))\n",
      "                else:\n",
      "                    axes[ii,jj].set_xticklabels([])\n",
      "\n",
      "                axes[ii,jj].set_xlim(xlim)\n",
      "                axes[ii,jj].set_ylim(ylim)\n",
      "\n",
      "    # adjust the spacing so the subplots are closer\n",
      "    fig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
      "    \n",
      "    return fig, axes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "idx = best_data['FEH_ADOP'] < -1\n",
      "metal_cut_stars = best_data[idx]\n",
      "other_stars = best_data[np.logical_not(idx)]\n",
      "\n",
      "f,a = color_color([other_stars[::10], metal_cut_stars[::10]], \n",
      "                  [dict(alpha=0.1, color='k'),dict(alpha=0.1, color='r')])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}